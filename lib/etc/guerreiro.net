FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-01
cascade_candidate_limit=1.00000000000000000000e+03
cascade_weight_multiplier=4.00000005960464477539e-01
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-01 5.00000000000000000000e-01 7.50000000000000000000e-01 1.00000000000000000000e+00 
layer_sizes=7 13 3 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (0, 0, 0.00000000000000000000e+00) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (7, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) (13, 4, 5.00000000000000000000e-01) (13, 4, 5.00000000000000000000e-01) (0, 0, 0.00000000000000000000e+00) 
connections (connected_to_neuron, weight)=(0, -6.91383779048919677734e-02) (1, 8.28263536095619201660e-02) (2, 8.23437497019767761230e-02) (3, 9.70739051699638366699e-02) (4, 9.28523615002632141113e-02) (5, -7.62187764048576354980e-02) (6, 6.33028224110603332520e-02) (0, 9.37151908874511718750e-03) (1, -2.98254340887069702148e-02) (2, -2.00821235775947570801e-02) (3, 7.46606066823005676270e-02) (4, -7.90564194321632385254e-02) (5, 3.97304221987724304199e-02) (6, -7.21973553299903869629e-02) (0, 8.81401821970939636230e-02) (1, 1.20868459343910217285e-02) (2, 3.83353605866432189941e-02) (3, 3.37029173970222473145e-02) (4, 2.41964235901832580566e-02) (5, -1.65206640958786010742e-02) (6, 9.55815389752388000488e-02) (0, 9.23200696706771850586e-03) (1, 6.69979080557823181152e-02) (2, 5.40517047047615051270e-02) (3, -7.08736628293991088867e-02) (4, 8.98790881037712097168e-02) (5, -1.37488692998886108398e-02) (6, -8.36976021528244018555e-02) (0, 6.81912973523139953613e-02) (1, 1.96681618690490722656e-02) (2, -1.69103816151618957520e-02) (3, -5.71043789386749267578e-03) (4, 4.12279367446899414062e-03) (5, 8.84293988347053527832e-02) (6, -3.69623303413391113281e-04) (0, 8.22364911437034606934e-02) (1, 7.70866870880126953125e-03) (2, 2.27261632680892944336e-02) (3, 7.68960937857627868652e-02) (4, 4.43247035145759582520e-02) (5, -6.46475851535797119141e-02) (6, -3.96302603185176849365e-02) (0, 6.14674761891365051270e-02) (1, 4.46403697133064270020e-02) (2, -5.40762394666671752930e-03) (3, 2.80414521694183349609e-03) (4, -8.90593975782394409180e-02) (5, 6.93318918347358703613e-02) (6, 1.88586562871932983398e-02) (0, -7.12876170873641967773e-02) (1, -3.88778112828731536865e-02) (2, 7.28977546095848083496e-02) (3, -3.25536951422691345215e-02) (4, -6.66327700018882751465e-02) (5, -6.13730587065219879150e-02) (6, 2.35053151845932006836e-03) (0, 1.57415419816970825195e-02) (1, -7.29691609740257263184e-02) (2, 4.14975211024284362793e-02) (3, 5.51158711314201354980e-02) (4, -8.03193449974060058594e-02) (5, 5.57312592864036560059e-02) (6, -6.37395679950714111328e-03) (0, 4.03686985373497009277e-02) (1, 5.47885373234748840332e-02) (2, -9.92313027381896972656e-02) (3, 9.77170243859291076660e-02) (4, -7.63465166091918945312e-02) (5, -3.79003956913948059082e-02) (6, 4.92117479443550109863e-02) (0, 7.35230520367622375488e-02) (1, -7.12229311466217041016e-02) (2, -6.04030303657054901123e-02) (3, 1.44430622458457946777e-02) (4, 4.59569022059440612793e-02) (5, 8.99206772446632385254e-02) (6, 4.79303970932960510254e-02) (0, -9.03636664152145385742e-02) (1, -7.00861439108848571777e-02) (2, 3.46383228898048400879e-02) (3, 4.31287959218025207520e-02) (4, 5.21512255072593688965e-02) (5, 9.93286147713661193848e-02) (6, 3.19617614150047302246e-02) (7, -1.25271156430244445801e-02) (8, -4.39804792404174804688e-03) (9, 9.68660190701484680176e-02) (10, 5.94129636883735656738e-02) (11, 4.39273193478584289551e-02) (12, -3.07034552097320556641e-02) (13, -2.69406810402870178223e-02) (14, 8.16540792584419250488e-02) (15, -5.85375241935253143311e-02) (16, 5.04904612898826599121e-02) (17, 9.06364545226097106934e-02) (18, -5.17724417150020599365e-02) (19, 6.07648566365242004395e-02) (7, 3.02079394459724426270e-02) (8, -9.21809747815132141113e-02) (9, 1.79248005151748657227e-02) (10, 7.54035189747810363770e-02) (11, 6.31396248936653137207e-02) (12, -4.23640012741088867188e-03) (13, 1.54672861099243164062e-02) (14, 7.62789919972419738770e-02) (15, 4.93345186114311218262e-02) (16, 4.78948429226875305176e-02) (17, 8.82092043757438659668e-02) (18, 8.15444216132164001465e-02) (19, -8.80112498998641967773e-03) 
